%\documentclass[11pt]{article}
\documentclass[preprint,11pt]{elsarticle}
%\usepackage{CJKutf8}
%\usepackage{hyperref}
%
%\hypersetup{hypertex=true,
%            colorlinks=true,
%            linkcolor=blue,
%            anchorcolor=blue,
%            citecolor=blue}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{ctable}
\usepackage{setspace}\singlespacing
\textheight 234mm \textwidth 155mm \oddsidemargin=0mm \headsep -1cm
\evensidemargin=0mm \baselineskip 38pt
\parindent 14pt
%\renewcommand\baselinestretch{1.3}
\usepackage{amsthm,amscd,amsfonts}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{float}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{ctex}
\usepackage{url}
%\usepackage{hyperref}
%\hypersetup{hypertex=true,
%            colorlinks=true,
%            linkcolor=blue,
%            anchorcolor=blue,
%            citecolor=blue}
\usepackage{appendix}
 %\renewcommand\theequation{ }
\usepackage{natbib}
\usepackage[ruled,linesnumbered]{algorithm2e}
\addtolength{\bibsep}{-1.5ex}%可以调整参考文献之间的行间距离
%\usepackage[dvipdfm,pdfborder={0 0 0},colorlinks=true,linkcolor=blue,CJKbookmarks=true]{hyperref}

%\renewcommand{\theequation}{\arabic{equation}}
\numberwithin{equation}{section}% the order of equation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% define some style
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{example}{Example}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{definition}{Definition}[section]

\newcommand{\sn}{\sum\limits_{j=1}^{n}}
\newcommand{\D}{\displaystyle}
\newcommand{\T}{\textstyle}
\newcommand{\q}{\quad}
\newcommand{\qq}{\qquad}
\def\f{\frac}
\providecommand{\liminf}{\mathop{\mathrm{lim\,inf}}}
\providecommand{\limsup}{\mathop{\mathrm{lim\,sup}}}
\providecommand{\ess}{\mathop{\mathrm{ess.\,sup}}}

\begin{document}
\begin{frontmatter}
\title{综合粒子群算法使用方法文档 \\ Synthetic PSO文档}
\author{刘欧}
\begin{abstract}
综合粒子群算法是一种基于粒子群算法并增加几种优化方式的新粒子群算法。综合粒子群算法在粒子群算法的基础上加入了自适应邻域、自适应惯性权重、交叉操作、概率接受最优解、叠加态变异以及信赖域变异，本文围绕后四种优化方式详细展开，综合粒子群算法同时还支持动态问题的最优解，本文讲述如何使用Syntheticpso.m函数对于问题进行求解以及对于Syntheticpso.m函数的参数调整。
\end{abstract}
\begin{keyword}粒子群算法;优化控制;参数设置
\end{keyword}
\end{frontmatter}
\newpage
\tableofcontents
\newpage
\section{基础参数设置}


由于在第$d$次迭代时，第$i$个粒子的\textbf{速度更新公式}如下：
\begin{eqnarray}
v_{i}^{d}&=&Inertia\times v_{i}^{d-1}\text{自适应惯性部分}
\\
&+&cSelf\times r_1\left( pbest_{i}^{d-1}-x_{i}^{d-1} \right) \text{个体学习部分}
\\
&+&cSocial\times r_2\left( gbest_{i}^{d-1}-x_{i}^{d-1} \right) \text{邻域学习部分}
\end{eqnarray}



Syntheticpso.m函数的基础设置包括：


$\bullet$\quad 最大迭代次数(Max Iteration):Syntheticpso.m函数的最大迭代次数


$\bullet$\quad 粒子个数(Swarm Size):一次迭代中粒子的个数


(注意:粒子群复杂度计算公式为$o(Particleswarm) =o(Swarm Size) \times o(Object function) \times o(Mutation)$故粒子个数应当控制在合理范围内，式中$o(Mutation)$表示变异所带来的额外复杂度。)



$\bullet$\quad 自适应惯性权重上下界(Inertia):自适应惯性权重的下界和上界(min Inertia 和 max Inertia)


$\bullet$\quad 个人学习因子大小(cSelf):个体学习部分在粒子群中所占据的权重


$\bullet$\quad 社会学习因子大小(cSocial):邻域学习部分在粒子群中所占据的权重


$\bullet$\quad 目标函数理想值(Object Target):所期盼得到的目标函数值(如果为min优化一般会设置为$-\infty$，如果为max优化一般设置为$\infty$)


$\bullet$\quad 优化选择项目($Judge \_ XXX$):选择是否进行优化，$XXX$代表优化类别，具体优化类别见后文介绍，如果想启用优化，请在$Judge \_ XXX$下输入true，不想启用请输入false。


$\bullet$\quad 最小邻域比例(min neighbor):按照比例确定最小的邻域范围，即粒子的最小邻域为($min neighbor \times Swarm Size$)


$\bullet$\quad 并行启用(Use Parallel):判断是否启用并行池，如果想启用并行请输入true，如果不想启用并行请输入false。(注意:启用并行后由于CPU核心使用较多可能会出现卡顿情况，并且对于启用并行的函数，读取Excel文档时不能使用xlsread函数并且不能声明全局变量。)


$\bullet$\quad 问题类型判断(Problem Type):判断求解问题的类型，若求解问题有额外的与迭代次数相关联的变量$t$导致函数在不同的迭代次数下具有不同的表达式，则该问题类型为动态问题(Dynamic Problem)，若无$t$ 变量则为静态问题。在基础设置中，如果问题类型为动态问题$Problem Type = True$，如果问题类型为静态问题$Problem Type = False$


$\bullet$\quad 打印设置(Display):打印粒子群运行状态，若$Display=0$则不打印粒子群运行状态，若$Display = 1$则依据DisplayInterval作为间隔打印粒子群运行状态


$\bullet$\quad 打印间隔DisplayInterval:见上文


由于Syntheticpso.m函数是一个针对动态问题开发的函数，在动态问题下由于目标函数随着迭代次数不断变化故不需要考虑粒子是否收敛，考虑到静态问题下若粒子群已然收敛但是没有收敛判断导致浪费时间与算力，特加入强制停止以及保险迭代功能于基础设置中。


$\bullet$\quad 强制停止(Foreclosure):当迭代次数大于等于保险迭代后，可以把强制停止由False改为True对于粒子群进行强制停止，修改后粒子进行完当时所在迭代后将会退出并返回最优解。


$\bullet$\quad 保险迭代(Insurance iteration):为防止进入下一次外层迭代或者下一次进行Syntheticpso.m函数时来不及修改强制停止设置而导致第一代就退出，特设置一个保险迭代来预防这种情况的出现。
\newpage
\section{综合粒子群算法}
\subsection{交叉}
\subsubsection{介绍}
在综合粒子群算法中，对于全部的$numparticle$个粒子，将会以$P_c$的概率进行交叉，即在每一次迭代中都有$numparticle \times P_c$个粒子执行交叉操作。

\subsubsection{交叉函数}
交叉函数模仿遗传算法中的交叉操作，对于被选中的粒子$A$和粒子$B$，在其所有的$nvars$个维度中随机选择两个分量$i$和$j$，并且保证$i < j$，对于粒子$A$和粒子$B$的第$i$个分量到第$j$个分量部分进行交叉。操作流程见Figure \ref{Fig:1}。
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=!]{Crossway.jpg}
\vspace{0.5cm}
\caption{\small 交叉方式}
\label{Fig:1}
\end{figure}
交叉方式的伪代码如Algorithm 1所示\\
\begin{algorithm}[H]
  \caption{Cross Function}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{$\boldsymbol{Velocities}$:A Matrix of size $numparticle \times nvars$ , $numparticle$ , $P_c$ , $nvars$}
  \KwOut{$\boldsymbol{newVelocities}$}
  $CrossNumber = numparticle * P_c$\;
  $Cross$ = $CrossNumber$ of particles are randomly selected among all particles\;
  \For{$k = \leftarrow 1$ to $CrossNumber$}{
    $i,j$ = Select $2$ integers at random from $1$ to $nvars$ and $i<j$\;
    $\boldsymbol{newVelocities}$(k,(i,j)) = $\boldsymbol{Velocities}$(k+1,(i,j))\;
    $\boldsymbol{newVelocities}$(k+1,(i,j)) =  $\boldsymbol{Velocities}$(k,(i,j))\;
    }
  return $\boldsymbol{newVelocities}$

  \label{A:1}
\end{algorithm}
\subsubsection{交叉方式的优化原理}
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=!]{WhyCrossBetter.jpg}
\vspace{0cm}
\caption{\small 交叉优化原理}
\label{Fig:2}
\end{figure}
Figure \ref{Fig:2}是一个问题$f(x)$的解空间等高线图，在同一颜色方框内的粒子具有相同大小的解，$A$和$B$是两个粒子，$v_A$和$v_B$是未进行交叉时粒子$A$和粒子$B$的速度，不难发现如果不进行交叉，粒子$A$和粒子$B$ 将不会经过$f(x)  = b$ 的区域，而对于$v_A$ 和$v_B$ 进行Figure \ref{Fig:2}所示平面所对应的两个分量的交叉后，$A$和$B$的位置将会更新在$f(x) = b$处，比原来的解更优。所以可以得知交叉方式的优化原理为将两个随机粒子之间的速度进行交叉，让其搜索原轨迹不会搜索的新位置，使解空间得到更加全面地搜索。
\subsubsection{综合粒子群算法中的交叉操作}
\label{Set.1}
在综合粒子群算法中，使用$Judge Cross$来开关交叉操作，并且对于交叉操作进行了一部分限制，如:设置了一个交叉起始迭代$Start Iteration$，以及一个交叉终止迭代$End Iteration$，此二者都可以在"参数设置.xlsx"的"Cross"部分进行调整，$Judge Cross$在"参数设置"的基础部分进行调整。


$\bullet$\quad 交叉概率($P_c$):$P_c$指粒子被选中进行交叉操作的概率，并非粒子中分量长度被交叉的概率


$\bullet$\quad 交叉起始迭代(Start Iteration):在粒子群迭代次数小于交叉起始迭代时，交叉将不会开始，同理可知当粒子群迭代次数大于交叉终止迭代时，交叉操作将会停止。
\subsection{接受函数}
\subsubsection{介绍}
在综合粒子群算法中，对于新解的接受函数灵感来自于模拟退火的接受函数，根据新旧解的大小，如果新解比旧解更优，则绝对接受新解，如果新解比旧解差，依照概率选择是否接受新解。
\subsubsection{接受函数}
接受函数仿照模拟退火算法中的接受函数，但是将其温度改为与迭代次数相挂钩的变量$Max Iteration - Iteration + k$，其中$Max Iteration$是最大迭代次数，$Iteration$是当前迭代次数，$k$是一个用来调整概率的参数。


当新解比旧解差时，接受函数如公式\ref{equ:1}所示：
\begin{equation}
p = \frac{1}{1+e^{\frac{\Delta}{Max Iteration - Iteration + k}}}
\label{equ:1}
\end{equation}
式中，$p$为接受概率，$\Delta = \left| NewFval - OldFval\right|$为新旧解之间的差。

接受函数的伪代码如Algorithm 2所示:\\
\begin{algorithm}[H]
  \caption{Accept Function}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{Individual best Fval :$\boldsymbol{IndividualFval}$ , New Fval :$\boldsymbol{Fval}$ , $numparticle$}
  \KwOut{New Individual best Fval :$\boldsymbol{IndividualFval}$}
  \For{$k = \leftarrow 1$ to $numparticle$}{
    \eIf{$\boldsymbol{Fval}$(k) is better than $\boldsymbol{IndividualFval}$(k)}{
    $\boldsymbol{IndividualFval}$(k) = $\boldsymbol{Fval}$(k)\;
    }{
    $\Delta$ = $\left|\boldsymbol{IndividualFval}(k) - \boldsymbol{Fval}(k)\right|$\;
    $p = \frac{1}{1+e^{\frac{\Delta}{Max Iteration - Iteration + k}}}$\;
    \eIf{$p > random$}{
    $\boldsymbol{IndividualFval}$(k) = $\boldsymbol{Fval}$(k)\;
    }{
    $\boldsymbol{IndividualFval}$(k) = $\boldsymbol{IndividualFval}$(k)\;
    }
    }
    }
  return $\boldsymbol{IndividualFval}$

  \label{A:2}
\end{algorithm}
\subsubsection{接受函数的优化原理}
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=!]{Accept.jpg}
\vspace{-0.5cm}
\caption{\small 接受函数优化原理}
\label{Fig:3}
\end{figure}
Figure \ref{Fig:3}是某个问题$f(x)$的解空间等高线图，在该迭代中，粒子$B$的新解$new B$的结果比旧解差，若没有接受函数的存在则会自动接受旧解，$A$和$C$将不会经过$f(x) = c$的情况，即$A$和$C$将不会经过更优解范围，但是若接受了新解$new B$，则会让$A$和$C$在下一次迭代中找到更优解$f(x) = c$，Figure \ref{Fig:3}仅仅展示了一种寻找到更优解的情况，还有很多使用接受函数得到更优解的情况。使用接受函数后，粒子会有更大的概率去探索其与其邻域内新接受的最优解之间的空间，并且由于概率较小，很多情况下不会发生，对于收敛性不会造成太大波动，这样可以更全面地搜索解空间。
\subsubsection{综合粒子群算法中的接受函数设置}
在综合粒子群算法中，使用$Judge Anneal$来开关接受函数，并且对于接受函数进行了一部分限制，如:设置了一个起始迭代$Start Iteration$，以及一个终止迭代$End Iteration$，此二者都可以在"参数设置.xlsx"的"Anneal" 部分进行调整，$Judge Anneal$在"参数设置"的基础部分进行调整。


$\bullet$\quad 接受函数参数k:与新解的接受概率呈现正相关趋势，并且需要大于等于0


$\bullet$\quad 起始迭代与交叉中的起始迭代(见Section \ref{Set.1})无异
\subsection{叠加态变异}
\subsubsection{介绍}
在综合粒子群算法中，叠加态变异的灵感来自于量子力学中的叠加态，对于某个粒子$A$，以其当前位置$Position_A$为均值，根据某个方差$\sigma ^2$分散成$Superposition$个叠加态粒子，对于所有的叠加态离子，选择最优的那个粒子作为观测态粒子进行坍缩。
\subsubsection{原理}
对于所有$numParticle$个粒子，依照$P_m$的概率选择$numParticle \times P_m$个粒子进行叠加态变异，被选中的粒子$A$首先保留自己的位置，后生成叠加态粒子集合$Superposition_A = \{A,A_1,A_2,\cdots,A_{Superposition-1}\}$，其中叠加态粒子集合 $ Superposition_A \sim \mathcal{N}(Position_A,\sigma^2)$。计算叠加态集合中每一个粒子所对应的函数值得到集合$Fval.Superposition_A $，该集合中最优解所对应的粒子即为观测态粒子。


由于粒子从叠加态进入观测态时位置与原位置发生了改变，为搜索更优解，对于速度也进行一次修改，对于粒子$A$，将初始状态的粒子$A$记为$initial A$，将最终得到的观测态粒子记为$new A$，为继续搜索观测态方向的解空间，将速度$v_A$以$v_A = Position_{initial A} - Position_{new A}$为更新公式进行变更。


叠加态变异函数的伪代码如Algorithm 3所示:\\
\begin{algorithm}[hpt]
  \caption{Superposition Function}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{ All particles' Position: $\boldsymbol{Position}$ , All particles' Velocity: $\boldsymbol{Velocities}$ , $P_m$ , $numparticle$ , $\sigma$ , Number of Superposition: $Superposition$ , lower bound: $lb$ , upper bound: $ub$   }
  \KwOut{New particles' Position: $\boldsymbol{NewPosition}$,New particles' Velocities: $\boldsymbol{NewVelocities}$}
  $Mutation Number$ =   $numparticle * P_m$\;
  $Mutation$ = $Mutation Number$ of particles are randomly selected among all particles\;
  \For{$k = \leftarrow 1$ to $Mutation Number$}{
    \For{$i = \leftarrow 1$ to $Superposition$}{
    \eIf{i =1}{
    $\boldsymbol{Superposition_k}(i)$ = $\boldsymbol{Position}(Mutation(i))$\;
    }{
    $\boldsymbol{Superposition_k}(i)$ $\sim$ $\mathcal{N}(\boldsymbol{Position}(Mutation(i)),\sigma^2)$\;
    }
    }
    Enforce bounds on $\boldsymbol{Superposition_k}$\;
    \For{$i = \leftarrow 1$ to $Superposition$}{
    $\boldsymbol{Fval.Superposition_A}(i) $ = Take $\boldsymbol{Superposition_k}(i)$ as parameter to calculate the value of the objective function\;
    }
    $\boldsymbol{NewPosition}(k)$ = $\boldsymbol{Superposition_k}(Position \, of \, min(Fval.Superposition_A))$\;
    $\boldsymbol{NewVelocities}(k)$ = $\boldsymbol{NewPosition}(k) - \boldsymbol{Position}(k)$\;
    }
    \For{$k = \leftarrow 1$ to $numparticle$}{
    \eIf{$k \in Mutation$}{
    $\boldsymbol{NewPosition}(k)$ and $\boldsymbol{NewVelocities}$ remain unchanged\;
    }{
    $\boldsymbol{NewPosition}(k)$ = $\boldsymbol{Position}(k)$\;
    $\boldsymbol{NewVelocities}(k)$ = $\boldsymbol{Velocities}(k)$\;
    }
    }
  return $\boldsymbol{NewPosition}$ , $\boldsymbol{NewVelocities}$
  \label{A:3}
\end{algorithm}
\subsubsection{叠加态变异优化原理}
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=!]{Superposition.jpg}
\vspace{-0.5cm}
\caption{\small 叠加态变异优化原理}
\label{Fig:4}
\end{figure}
Figure \ref{Fig:4}是某个问题$f(x)$的解空间等高线图，自左到右为粒子$A$从初始状态进入叠加态而后又从叠加态转变为观测态的过程，解的优劣关系延续Figure \ref{Fig:3}中解的关系。自左向右粒子$A$先从初始状态依照高斯分布分散出包括自己在内的$6$个叠加态粒子，在被观测时从$6$个叠加态粒子坍缩为观测态粒子$new A$，新速度也为$initial A$到$new A$之间的向量减法。
\subsubsection{综合粒子群算法中的叠加态变异操作}
在综合粒子群算法中，叠加态变异的开关为$Judge Superposition$，当其为$true$时开启叠加态，当其为$false$时关闭叠加态。此外在"Superposition"设置中添加了控制变异起始迭代$Mut Start Iteration$，$P_m$，叠加态粒子个数$Superposition$以及标准差$\sigma$。

$\bullet$\quad 叠加态粒子个数(Superposition):粒子进入叠加态时分出的粒子个数


$\bullet$\quad 标准差($\sigma$):叠加态粒子的标准差(服从高斯分布)


$\bullet$\quad 变异概率($P_m$):粒子进行变异的概率


$\bullet$\quad 变异起始迭代(Mut Start Iteration):和交叉的起始迭代类似(见Section\ref{Set.1})
\subsection{信赖域变异}
\subsubsection{介绍}
信赖域算法是一种求解非线性优化问题的数值方法。信赖域算法是一种迭代算法，即从给定的初始解出发，通过逐步迭代，不断改进，直到获得满意的近似最优解为止。其基本思想是把最优化问题转化为一系列简单的局部寻优问题。
\subsubsection{原理}
对于一个优化目标函数$f$，设置搜索初值为$\boldsymbol{x_0}$，设置一个信赖域半径$\Delta_0$，最高迭代次数为$N$，开始迭代。


对于第$k$次迭代时，根据此时的信赖域半径$\Delta_k$构建信赖域$\Omega_k = \{x\in R^n | \left\|x - x_k\right\|\leq  \Delta_k\}$。


对于目标函数$f$，其在极值点处近似于二次近似函数$q^{(k)}(s)$，因此对于无约束时，可以利用二次逼近，构造如下的信赖域子问题：
\begin{eqnarray*}
\min\quad q^{(k)}(\boldsymbol{s}) &=& f(\boldsymbol{x_k}) + grad^{T}_{k}\boldsymbol{s} + \frac{1}{2}(\boldsymbol{s}^T H_{k} \boldsymbol{s})\\
s.t. \quad \left\| \boldsymbol{s} \right\| _2  &\leq&  \Delta_k
\end{eqnarray*}
式中，$grad_{k}$是当前目标函数$f$在点$\boldsymbol{x_k}$处的梯度;$\boldsymbol{s} = \boldsymbol{x} - \boldsymbol{x_k}$;$H_k$为$f$在点$\boldsymbol{x_k}$处的Hesse矩阵。


假设$\boldsymbol{s_k}$为该子问题的解。目标函数$f$在第$k$步的实际下降量(观测下降长度)为
\begin{equation}
Ared_k = f(\boldsymbol{x_k}) - f(\boldsymbol{x_k} + \boldsymbol{s_k})
\end{equation}
二次近似函数$q^{(k)}(s)$的预测下降量(预计下降长度)为
\begin{equation}
Pred_k = q^{(k)}(0) - q^{(k)}(\boldsymbol{s_k})
\end{equation}
根据观测下降长度与预测下降长度的比值$r_k$得到评价信赖域在下一次迭代时的半径$\Delta_{k+1}$


若$r_k \rightarrow 1$，则二次近似函数与目标函数的接近程度好。这个时候应当适当扩大信赖域范围。


若$r_k \rightarrow 0$，则二次近似函数与目标函数的接近程度差。这个时候应当适当缩小信赖域范围。


若$r_k$无显著表现，则不改变信赖域范围。
\\
\\
\noindent 一般而言，当$r_k \geq 0.75$， 认为 $r_k \rightarrow 1$; 当$r_k \leq 0.25$,认为 $r_k \rightarrow 0$。
\subsubsection{加入约束条件}
若是具有等式约束条件，则可以参考拉格朗日乘数法，构造拉格朗日函数对于近似函数进行改进。


对于具有不等式约束的条件，将会转换成 Karush-Kuhn-Tucker (KKT) 方程\cite{wu2007karush}进行求解。
\subsubsection{信赖域变异函数}
对于所有$numParticle$个粒子，依照$P_m$的概率选择$numParticle \times P_m$个粒子进行以$Max Iteration$为上限的信赖域变异，为充分搜索解空间，选择其在信赖域中最后一次迭代时的梯度方向作为其变异后的速度方向。


信赖域变异的伪代码如Algorithm 4所示:\\
\begin{algorithm}[ht]
  \caption{Trust-region Function}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{ All particles' Position: $\boldsymbol{Position}$ , All particles' Velocity: $\boldsymbol{Velocities}$ , $P_m$ , $numparticle$ , $Max Iteration$ , lower bound : $lb$ , upper bound : $ub$ }
  \KwOut{New particles' Position: $\boldsymbol{NewPosition}$,New particles' Velocities: $\boldsymbol{NewVelocities}$}
  $Mutation Number$ =   $numparticle * P_m$\;
  $Mutation$ = $Mutation Number$ of particles are randomly selected among all particles\;
  \For{$k = \leftarrow 1$ to $Mutation Number$}{
    \For{$i =\leftarrow 1$ to $Max Iteration$}{
    Trust region optimization $Position(Mutation(k))$ and enforce bounds on optimized parameter\;
    \If{i = Max Iteration}
    {
    grad = the gradient in this iteration\;
    }
    }
    $\boldsymbol{NewPosition}(k)$ = Trust-region optimization result vector\;
    $\boldsymbol{NewVelocities}(k)$ = grad\;
    }
    \For{$k = \leftarrow 1$ to $numparticle$}{
    \eIf{$k \in Mutation$}{
    $\boldsymbol{NewPosition}(k)$ and $\boldsymbol{NewVelocities}$ remain unchanged\;
    }{
    $\boldsymbol{NewPosition}(k)$ = $\boldsymbol{Position}(k)$\;
    $\boldsymbol{NewVelocities}(k)$ = $\boldsymbol{Velocities}(k)$\;
    }
    }
  return $\boldsymbol{NewPosition}$ , $\boldsymbol{NewVelocities}$
  \label{A:4}
\end{algorithm}
\subsubsection{信赖域变异的优化原理}
\begin{figure}[ht]
\centering
\includegraphics[width=15cm,height=!]{trust.jpg}
\vspace{-0.5cm}
\caption{\small 信赖域变异优化原理}
\label{Fig:5}
\end{figure}
Figure \ref{Fig:5}是某个问题$f(x)$的解空间等高线图，其中$A$为被选中进行信赖域变异的粒子，$B$为普通粒子，解的优劣仍延续Figure \ref{Fig:3}中解的关系。自左向右看可以发现粒子$A$原本的轨迹中是不会经过可以使用信赖域变异进行优化的解空间，粒子$A$经过信赖域变异后逐步优化最终超过了原本比其更优的粒子$B$，并且因为最大迭代次数的限制无法达到更优解，为搜索可能存在的更优解区域，将最后一次迭代时的梯度方向$grad_{f(new A)}$ 作为粒子的速度。限制最大迭代次数的原因在于避免粒子过早陷入局部最优解。



信赖域变异的原理在于创造了局部最优解对于粒子的牵引能力，使部分原本进行半盲目搜索的粒子可以被解吸引，从而使粒子更为全面并且更为便捷地搜索解空间。
\subsubsection{综合粒子群算法中的信赖域变异操作}
在综合粒子群算法中，信赖域变异的开关为$Judge Trust-region$，当其为$true$时开启信赖域变异，当其为$false$时关闭信赖域变异。此外在"trust-region"设置中添加了控制变异起始迭代$Mut Start Iteration$，$P_m$，最大迭代次数$Max Iteration$以及并行开关$UseParallel$。


$\bullet$\quad 变异概率($P_m$):粒子被选择进行信赖域变异的概率


$\bullet$\quad 最大迭代次数(Max Iteration):进行信赖域变异的粒子在信赖域算法中的最大迭代次数


$\bullet$\quad 并行开关(Use Parallel):设置与基础设置一致


$\bullet$\quad 变异起始迭代(Mut Start Iteration):和交叉的起始迭代类似(见Section\ref{Set.1})
\subsection{几种优化的缺陷}
交叉操作与接受函数的参数调节不当可能会导致无法产生更优解，建议$P_c = 0.15$，$k = 300$。


两种变异操作的算法复杂度极高，对于算法的运行速度具有着极大的影响。建议在控制好各个参数的前提下使用。


\begin{eqnarray*}
o(trust-region) &=& o(Object Function) \times (1 + MaxIteration \times (P_m \times numparticle)) \\
o(Superposition) &=& o(Object Function) \times (1 + Superposition \times (P_m \times numparticle))
\end{eqnarray*}
\newpage
\section{综合粒子群算法在动态问题中的应用}
\subsection{问题介绍}
考虑目标函数$f(\boldsymbol{x},t)$，其中$\boldsymbol{x}$为需要优化的向量，$t$为一个与$x$无关并且只和时间有关的额外维度，要求在$t$不断变动的前提下尽量得到每一个$t$下的参数$\boldsymbol{x}_t$使其能够让$f(\boldsymbol{x},t)$最优。

\subsection{对于动态问题的求解}
由于$t$是一个只与时间有关而与$\boldsymbol{x}$无关的一个额外维度，所以不妨将粒子群算法的迭代次数$Iteration$引入充当一个时间维度。


如何求解这样一个$f(\boldsymbol{x},t)$呢?可以将迭代次数扩充进粒子中进行求解。


对于求解器solve进行如Algorithm 5所示伪代码的改动:\\
\begin{algorithm}[H]
  \caption{solve change for dynamic problem}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{$numparticle$ , $Problemtype$ if it is a dynamic problem Problemtype = true , All particles' Position: $\boldsymbol{Position}$ , Object function}
  \KwOut{$\boldsymbol{newFvals}$}
  \eIf{$Problemtype$ = true}{
  \For{$i = \leftarrow 1$ to $numparticle$}{
  $\boldsymbol{newFvals}$(i) = Object function([$\boldsymbol{Position}$(i,:),Iteration])\;
  }
  }
  {
  \For{$i = \leftarrow 1$ to $numparticle$}{
    $\boldsymbol{newFvals}$(i) = Object function(Position(i,:))\;
  }

  }
  return $\boldsymbol{newFvals}$

  \label{A:5}
\end{algorithm}
更新求解器$solve$后便可以对于目标问题进行优化求解，并且可以使用交叉操作、接受函数以及叠加态变异三种优化方式。


对于信赖域变异，由于信赖域算法与普通求解器不同，所以需要对其求解器进行额外改造


对于信赖域变异函数，进行如Algorithm 6所示伪代码的改动:\\
\begin{algorithm}[H]
  \caption{trust-region change for dynamic problem}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{$numparticle$ , $Problemtype$ if it is a dynamic problem Problemtype = true , All particles' Position: $\boldsymbol{Position}$ , Object function}
  \KwOut{$\boldsymbol{newFvals}$}
  \eIf{$Problemtype$ = true}{
  \For{$i = \leftarrow 1$ to $numparticle$}{
  Trust region optimization [$\boldsymbol{Position}$(i,:),Iteration] and enforce bounds on optimized parameter,\;
  For the number of iterations, build a constraint that keeps the number of iterations unaffected which is The last parameter - Iteration = 0\;
  }
  }
  {
  \For{$i = \leftarrow 1$ to  $numparticle$}{
  Trust region optimization $Position(Mutation(k))$ and enforce bounds on optimized parameter\;
  }

  }
  return $\boldsymbol{newFvals}$

  \label{A:6}
\end{algorithm}
\subsection{信赖域变异在动态问题求解中的作用}
由于动态问题中目标函数$f(\boldsymbol{x},t)$的$t$会发生变动，于是在每一次迭代中目标函数都几乎会是一个全新的函数，但是由微分法可知在$t$的变化足够缓慢时($dt$)，我们可以将目标函数视为几乎没有变化($f(\boldsymbol{x},t+dt) - f(\boldsymbol{x},t) \to 0$)。


在$t$的变化为$dt$时，$f(\boldsymbol{x},t)$的变化为
\begin{equation}
f(\boldsymbol{x},t+dt) = \frac{\partial f\left( \boldsymbol{x},t \right)}{\partial t}dt\,\,+\,\,f\left( \boldsymbol{x},t \right)
\end{equation}
可见函数的变化是由$\frac{\partial f\left( \boldsymbol{x},t \right)}{\partial t}$ 与$dt$共同决定的，由于函数对于$t$的偏导数不尽相同，对于解空间的干扰比较难处理，但是函数变化后，其解空间发生相应的变化与$dt$ 是有直接关系的。Figure \ref{Fig:6}展现了一种可能的解空间变化与$dt$之间的关系。
\begin{figure}[H]
\centering
\includegraphics[width=12cm,height=!]{dynamic.jpg}
\vspace{-0.5cm}
\caption{\small dt大小对于解空间的变化的影响}
\label{Fig:6}
\end{figure}

其对于解空间中局部最优解范围的影响由$dt$的大小决定，当$dt$小于某一阈值$\varepsilon$内时，当前粒子$A$进行信赖域变异时，仍然可以被其在上一次迭代中所处的局部最优解空间吸引，但若$dt$过大，会导致$A$不再能寻找到上一次所处的局部最优解空间，信赖域变异效果变差。


在动态问题中，对于信赖域变异方式的伪代码进行如Algorithm 7所示调整以便寻找局部最优解:\\
\begin{algorithm}[hpt]
  \caption{Trust-region particle selection change}
  \SetKwData{Left}{left}
  \SetKwData{This}{this}
  \SetKwData{Up}{up}
  \SetKwFunction{Union}{Union}
  \SetKwFunction{FindCompress}{FindCompress}
  \SetAlgoLined
  \KwIn{ All particles' Fvals: $\boldsymbol{Fvals}$ , $P_m$ , $numparticle$ , $Max Iteration$ }
  \KwOut{$Mutation$}
  $Mutation Number$ =   $numparticle * P_m$\;
  $Mutation$ = $Mutation Number$ of particles are randomly selected among all particles\;
  \If{$Mutation\, \cap \,{number of min(\boldsymbol{Fvals})} = \varnothing$}{
  Convert a position in $Mutation$ to the number of min($\boldsymbol{Fvals}$)\;
  }
  \label{A:7}
\end{algorithm}


信赖域变异在动态问题中的长处便在于上一代的最优粒子$A$可以较为轻松地找到其上一次迭代所处的局部最优解，并且还有其他的几个随机粒子寻找其他地区的局部最优解，哪怕$A$所处的局部最优解在后来的迭代中恶化，其他粒子找到的新局部最优解也能代替$A$发挥作用。

\subsection{对比}
\subsubsection{设置}
本文使用三种设置对于同一个动态问题进行求解，选择其最优解所构成的曲线进行对比。三种设置的对比如\ref{Tab:1}所示，由于篇幅限制，仅展示不同的部分。
\begin{table}[b]
  \centering
  \caption{option}
    \begin{tabular}{lccc}
    \toprule
          & Only PSO & Syntheticpso / Mutation  & Syntheticpso \\
    \midrule
    Min Inertia & 0.65  & 0.01  & 0.01 \\
    Max Inertia & 0.65  & 1.3   & 1.3 \\
    Judge Trust-region & FALSE & FALSE & TRUE \\
    Judge Anneal & FALSE & TRUE  & TRUE \\
    Judge Cross & FALSE & TRUE  & TRUE \\
    \bottomrule
    \end{tabular}%
  \label{Tab:1}%
\end{table}%
Only PSO 表示最基本的PSO算法，Syntheticpso / Mutation表示变异不开启的综合粒子群算法，Syntheticpso表示除叠加态变异外均开启的综合粒子群算法。
\subsubsection{目标问题}
目标问题为一个$f(\boldsymbol{x},t)$函数，其表达式(函数图像见附件)为:
\begin{equation}
f(\boldsymbol{x},t) = \frac{1}{4000}\sum_{i = 1}^{D} (x_i^2\sin{t}) - \prod_{i = 1}^{D}\cos\frac{x_i}{\sqrt{t}}
\end{equation}
其中，$D=2$，$x_i$的上下界均为$[-10,10]$，$t = \frac{Iteration}{20}$，粒子群迭代次数设置为$500$代。

\subsubsection{结果比较}
对于目标问题进行优化后得到三组结果如Figure \ref{Fig:7}所示:
\begin{figure}[H]
\centering
\includegraphics[width=12cm,height=!]{Compare.jpg}
\vspace{-0.5cm}
\caption{\small 三种不同粒子群算法对于目标问题的求解结果比较}
\label{Fig:7}
\end{figure}
不难发现最基本的PSO算法比起加入了优化方式的PSO算法在处理动态问题上显得捉襟见肘，难以得到如另外两种算法所示的更优解。


不开启信赖域变异的综合粒子群算法虽然可以求得较优解但是极不稳定，很难保持最优状态。


而开启了信赖域变异的综合粒子群算法具有稳定，可以求得满意解等特点，在Figure \ref{Fig:7}中出现剧烈波动的部分应当为之前所述的最优粒子丢失局部最优解的情况，但是在较短次数的迭代后，其他粒子可以接替之前的最优粒子继续寻找全局最优解来保持稳定，说明了信赖域变异在求解动态问题时具有一定的优越性。


根据附件的函数随时间变换的图像视频可以得到，进行了信赖域变异的综合粒子群算法在测试函数中绝大部分时间都可以稳定地找到全局最优解，而单纯粒子群算法或者变异不开启的综合粒子群算法都不能稳定地找到全局最优解或者容易陷入局部最优解。
\newpage
\section{参考文献}
\bibliographystyle{elsart-num}
\bibliography{References}
\end{document}
